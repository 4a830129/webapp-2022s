<!DOCTYPE html>
<html lang="zh-TW">
  <head>
    <title>Week 03 - 課堂作業 01</title>
    <meta charset="UTF-8" />
  </head>

  <body>
    <a href="https://pyecontech.com/2020/04/19/knn/" target="_blank">
        [本文來源] ： https://pyecontech.com/2020/04/19/knn/
    </a><br><br>

<h1>K-近鄰演算法 KNN</h1>

<h2>什麼是KNN?</h2>

<p>
  簡單來說，就是物以類聚的概念。如果你的鄰居10戶有8戶是有錢人，那你十之八九也是有錢人! KNN用途很廣，適用於離散型資料，也適用於連續型資料。
</p>

<h2>KNN的運作模式</h2>

<p><strong>找到距離最近的K個鄰居→進行投票→決定類別</strong></p>

主要運作模式分為3步驟:

步驟1. 計算每個點之間的距離
步驟2. 用K值決定鄰居數目，並進行投票 (在連續型資料中，則是計算平均數)
步驟3. 以投票結果決定類別
距離計算
點與點之間的距離，除了我們直觀用尺量以外，數學上其實還有很多種符合距離定義的其他計算方式，以下我們簡單分享幾種。

歐基里德距離 (Euclidean distance)
這其實就是我們平時最熟悉的距離計算模式:

<p>把方程式的圖檔加在這裡</p>

曼哈頓距離 (Manhattan distance)
曼哈頓距離的計算方式是將所有特徵的個別距離加總在一起:

<p>把方程式的圖檔加在這裡</p>

明氏距離 (Minkowski distance)
有點像是歐基里德距離與曼哈頓距離的推廣，仔細對照公式會發現，當p=1時其實就是曼哈頓距離，而當p=2時則為歐基里德距離。在這邊，p為任意常數。

<p>把方程式的圖檔加在這裡</p>

</body>